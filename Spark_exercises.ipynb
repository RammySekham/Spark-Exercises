{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MYFIRSTRY', 'WILLROCK', 'MYLITTLEBIGFATWORLD']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Map Function in Spark\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"myfirsttry\") #Sparkcontext is the entry point for spark environment.\n",
    "                                                #For every sparkapp you need to create the sparkcontext object.\n",
    "data = ['myfirstry', 'willrock', 'mylittlebigfatworld']\n",
    "distributed_data = sc.parallelize(data) \n",
    "distributed_data.map(lambda x:x.upper()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SparkConf and SparkSession\n",
    "#Sparkconf is the class which gives you the various option to provide configuration parameters.\n",
    "# Val Conf = new sparkConf().setMaster(“local[*]”).setAppName(“test”)\n",
    "# Val SC  = new sparkContext(Conf) #spark configuration is passed to spark context. \n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparkSession is an entry point to Spark and creating a SparkSession instance would be the \n",
    "# first statement you would write to program with RDD, \n",
    "# DataFrame and Dataset. SparkSession will be created using SparkSession.builder() builder patterns.\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"myfirstapp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.name', 'myfirstapp'),\n",
       " ('spark.app.id', 'local-1608764110915'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.port', '52227'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.host', 'DESKTOP-DVCMFLI')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-DVCMFLI:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>myfirstapp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x21416494f40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Spark DataFrame\n",
    "path = \"data/sparkify_log_small.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[artist: string, auth: string, firstName: string, gender: string, itemInSession: bigint, lastName: string, length: double, level: string, location: string, method: string, page: string, registration: bigint, sessionId: bigint, song: string, status: bigint, ts: bigint, userAgent: string, userId: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(artist='Showaddywaddy', auth='Logged In', firstName='Kenneth', gender='M', itemInSession=112, lastName='Matthews', length=232.93342, level='paid', location='Charlotte-Concord-Gastonia, NC-SC', method='PUT', page='NextSong', registration=1509380319284, sessionId=5132, song='Christmas Tears Will Fall', status=200, ts=1513720872284, userAgent='\"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"', userId='1046')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|       artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page| registration|sessionId|                song|status|           ts|           userAgent|userId|\n",
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|Showaddywaddy|Logged In|  Kenneth|     M|          112|Matthews|232.93342| paid|Charlotte-Concord...|   PUT|NextSong|1509380319284|     5132|Christmas Tears W...|   200|1513720872284|\"Mozilla/5.0 (Win...|  1046|\n",
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              artist|\n",
      "+--------------------+\n",
      "|       Showaddywaddy|\n",
      "|          Lily Allen|\n",
      "|Cobra Starship Fe...|\n",
      "|          Alex Smoke|\n",
      "|                null|\n",
      "|                null|\n",
      "|              Redman|\n",
      "|     Ulrich Schnauss|\n",
      "|                null|\n",
      "|                null|\n",
      "|               Jay-Z|\n",
      "|         Evanescence|\n",
      "|     Scissor Sisters|\n",
      "|        3 Doors Down|\n",
      "|       George Younce|\n",
      "|              Aly-Us|\n",
      "|                null|\n",
      "|            BjÃÂ¶rk|\n",
      "|      David Bromberg|\n",
      "|          Nickelback|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"artist\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|           artist|\n",
      "+-------+-----------------+\n",
      "|  count|             8347|\n",
      "|   mean|            461.0|\n",
      "| stddev|            300.0|\n",
      "|    min|              !!!|\n",
      "|    max|ÃÂlafur Arnalds|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(\"artist\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression cannot contain assignment, perhaps you meant \"==\"? (<ipython-input-23-318b3510c2ad>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-318b3510c2ad>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    df = df.dropna(\"how\" = any, subset=['sessionid','userid'])\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(\"how\" = any, subset=['sessionid','userid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            page|\n",
      "+----------------+\n",
      "|           About|\n",
      "|       Downgrade|\n",
      "|           Error|\n",
      "|            Help|\n",
      "|            Home|\n",
      "|           Login|\n",
      "|          Logout|\n",
      "|        NextSong|\n",
      "|   Save Settings|\n",
      "|        Settings|\n",
      "|Submit Downgrade|\n",
      "|  Submit Upgrade|\n",
      "|         Upgrade|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"page\").dropDuplicates().sort(\"page\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Starting Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('mytinytinyapp').getOrCreate()\n",
    "path = \"data/sparkify_log_small.json\"\n",
    "df = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(artist='Showaddywaddy', auth='Logged In', firstName='Kenneth', gender='M', itemInSession=112, lastName='Matthews', length=232.93342, level='paid', location='Charlotte-Concord-Gastonia, NC-SC', method='PUT', page='NextSong', registration=1509380319284, sessionId=5132, song='Christmas Tears Will Fall', status=200, ts=1513720872284, userAgent='\"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"', userId='1046', hour='9')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use of UDF ( User Defined Functions)\n",
    "from pyspark.sql.functions import udf\n",
    "import datetime\n",
    "get_hour = udf(lambda x: datetime.datetime.fromtimestamp(x/1000.0). hour)\n",
    "df1 = df.withColumn(\"hour\", get_hour(df.ts))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use of Filter, groupby, count, order by in one query\n",
    "songs_per_hour = df1.filter(df1.page=='NextSong').groupby('hour').count().orderBy(df1.hour.cast(\"float\"))\n",
    "df2=songs_per_hour.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, sessionid: bigint, song: string]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.select(['userId', 'sessionid', 'song']).where(df1.userId=='1138')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use of Window functions\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import count\n",
    "screen = Window.partitionBy(\"userId\").orderBy(desc('ts')).rangeBetween(Window.unboundedPreceding, 0)\n",
    "df1 = df1.withColumn('newcolumn', count('song').over(screen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(page='Error')\n",
      "Row(page='Downgrade')\n",
      "Row(page='Help')\n",
      "Row(page='Submit Downgrade')\n",
      "Row(page='Settings')\n",
      "Row(page='Logout')\n",
      "Row(page='Save Settings')\n",
      "Row(page='Home')\n",
      "Row(page='NextSong')\n",
      "Row(page='Upgrade')\n",
      "Row(page='Submit Upgrade')\n",
      "Row(page='About')\n"
     ]
    }
   ],
   "source": [
    "### Question 1 : Which page did user id \"\" (empty string) NOT visit?\n",
    "pages = df.select(\"page\").dropDuplicates()\n",
    "visited = df.select(\"page\").dropDuplicates().where(df.userId == \"\")\n",
    "for row in set(pages.collect())-set(visited.collect()):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| page|\n",
      "+-----+\n",
      "|Login|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Question 2: What type of user does the empty string user id most likely refer to?\n",
    "visited.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Question 3: How many female users do we have in the data set?\n",
    "df.filter(df.gender=='F').select('userId', 'sessionId').dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|  artist|acount|\n",
      "+--------+------+\n",
      "|Coldplay|    83|\n",
      "+--------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Question 4: How many songs were played from the most played artist?\n",
    "df.filter(df.page==\"NextSong\").select('artist').groupBy('artist').agg({'artist':'count'})\\\n",
    "    .withColumnRenamed('count(Artist)', 'acount').sort(desc('acount')).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+--------+------+\n",
      "|userId|           ts|    page|H_Flag|\n",
      "+------+-------------+--------+------+\n",
      "|   999|1513758639284|NextSong|     0|\n",
      "|   999|1513728737284|NextSong|     0|\n",
      "|   999|1513728409284|NextSong|     0|\n",
      "|   998|1513783746284|NextSong|     0|\n",
      "|   998|1513783633284|NextSong|     0|\n",
      "|   998|1513783395284|NextSong|     0|\n",
      "|   998|1513783160284|NextSong|     0|\n",
      "|   998|1513782927284|NextSong|     0|\n",
      "|   998|1513782569284|NextSong|     0|\n",
      "|   998|1513780913284|NextSong|     0|\n",
      "|   989|1513766235284|NextSong|     0|\n",
      "|   989|1513765531284|NextSong|     0|\n",
      "|   989|1513765265284|NextSong|     0|\n",
      "|   989|1513765082284|NextSong|     0|\n",
      "|   988|1513754017284|NextSong|     0|\n",
      "|   988|1513753822284|NextSong|     0|\n",
      "|   986|1513775128284|NextSong|     0|\n",
      "|   986|1513774892284|NextSong|     0|\n",
      "|   986|1513774709284|NextSong|     0|\n",
      "|   986|1513756172284|NextSong|     0|\n",
      "+------+-------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##How many songs do users listen to on average between visiting our home page? \n",
    "##Please round your answer to the closest integer.\\\n",
    "\n",
    "#let us make a new column which flags when user visit home\n",
    "\n",
    "path = \"data/sparkify_log_small.json\"\n",
    "df = spark.read.json(path)\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "Home_Flag = udf(lambda x: int(x=='Home'), IntegerType())\n",
    "\n",
    "df1 = df.filter((df.page=='NextSong') | (df.page=='home'))\\\n",
    "        .select('userId', 'ts', 'page')\\\n",
    "        .withColumn('H_Flag', Home_Flag('page'))\\\n",
    "        .orderBy(desc('userId'), desc('ts'))\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Partition by userid\n",
    "##count nextSong instances( when user listens to a song) between ''HomeFlag =1' intervals\n",
    "\n",
    "## Make Home Flag intervals, 1, 2, 3 ..... so on, on home_visit by userid\n",
    "\n",
    "from pyspark.sql.functions import sum as fsum\n",
    "\n",
    "screen = Window.partitionBy(df1.userId)\\\n",
    "         .orderBy(desc('ts'))\\\n",
    "         .rangeBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "intervals = df1.withColumn('interval', fsum('H_Flag').over(screen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|avg(count(interval))|\n",
      "+--------------------+\n",
      "|    9.87810650887574|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Count song instances for each interval\n",
    "intervals.filter((intervals.page == 'NextSong')) \\\n",
    "    .groupBy('userId', 'interval') \\\n",
    "    .agg({'interval':'count'}) \\\n",
    "    .agg({'count(interval)':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
